\chapter{Conclusion}
\begin{markdown}

This report describes PTX.jl, a library for tranlating vector
functions in the Julia programming language to code that can execute
on a NVIDIA GPU. The library is built using both Julia and the LLVM
compiler infrastructure, utilizing the NVPTX backend. The results in
Chapter \ref{chap:res} shows that the resulting code is as performant
as equivalent code written in CUDA and OpenCL C. Comparisons with
current Julia CPU implementations of Matrix Multiplication also
indicates that there is a possibility to offload even isolated and
relative small computations to the GPU.

The results indicate that the unboxing of arrays approach taken by the
PTX.jl library does not incure a loss of performance over lower level
language implementations. The programmer productivity have been
improved by moving to a dynamic language and enabling users of a high
level language to use the same language to define kernels. 

PTX.jl enables using the existing GPU libraries written for Julia
without modification.

\end{markdown}
